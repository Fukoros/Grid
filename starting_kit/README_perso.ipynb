{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'example_submission/'\n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "input_dir = 'public_data/'\n",
    "output_dir = 'output/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir);\n",
    "path.append(input_dir); path.append(output_dir);\n",
    "%matplotlib inline\n",
    "# Uncomment the next lines to auto-reload libraries (this causes some problem with pickles in Python 3)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chronics  configuration.yaml  reference_grid.m\r\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'public_data/hard'              # Change this to the directory where you put the input data\n",
    "!ls $data_dir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ====================================================\n",
      "                     GAME PARAMETERS\n",
      "  ====================================================\n",
      "    loadflow_backend: pypower\n",
      "    loadflow_mode: AC\n",
      "    n_timesteps_consecutive_soft_overflow_breaks: 10\n",
      "    n_timesteps_hard_overflow_is_broken: 10\n",
      "    n_timesteps_horizon_maintenance: 48\n",
      "    max_number_loads_game_over: 6\n",
      "    hard_overflow_coefficient: 1.0\n",
      "    n_timesteps_soft_overflow_is_broken: 10\n",
      "    max_seconds_per_timestep: 1.0\n",
      "    max_number_prods_game_over: 3\n",
      "  ====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypownet.environment\n",
    "import pypownet.runner\n",
    "data_dir = 'public_data'  \n",
    "environment = pypownet.environment.RunEnv(parameters_folder=os.path.abspath(data_dir),\n",
    "                                              game_level=\"hard\",\n",
    "                                              chronic_looping_mode='natural', start_id=0,\n",
    "                                              game_over_mode=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring metric: reward\n"
     ]
    }
   ],
   "source": [
    "from scoring_program import libscores\n",
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.123283386230469e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAgent(pypownet.agent.Agent):\n",
    "    \"\"\"\n",
    "    An example of a baseline controler that randomly switches the status of one random power line per timestep (if the\n",
    "    random line is previously online, switch it off, otherwise switch it on).\n",
    "    \"\"\"\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "    \n",
    "    def act(self, observation):\n",
    "        \"\"\" Produces an action given an observation of the environment. Takes as argument an observation of the current\n",
    "        power grid, and returns the chosen action.\"\"\"\n",
    "        # Sanity check: an observation is a structured object defined in the environment file.\n",
    "        assert isinstance(observation, pypownet.environment.Observation)\n",
    "        #print(\" DO NOTHING AGENT !!! \")\n",
    "        action_space = self.environment.action_space\n",
    "\n",
    "        # Implement your policy here\n",
    "        # Example of the do-nothing policy that produces no action (i.e. an action that does nothing) each time\n",
    "        do_nothing_action = action_space.get_do_nothing_action()\n",
    "\n",
    "        # Sanity check: verify the good overall structure of the returned action; raises exceptions if not valid\n",
    "        assert action_space.verify_action_shape(do_nothing_action)\n",
    "        return do_nothing_action\n",
    "\n",
    "        # No learning (i.e. self.feed_reward does pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative rewards : -362.6689729381084\n",
      "12.930731534957886\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import time\n",
    "start = time.time()\n",
    "NUMBER_ITERATIONS = 1000\n",
    "\n",
    "submission_dir = 'example_submission'\n",
    "sys.path.append(submission_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "log_path = os.path.abspath(os.path.join(output_dir, 'runner.log'))\n",
    "\n",
    "\n",
    "open(log_path, 'w').close()\n",
    "submitted_controler = CustomAgent(environment)\n",
    "# Instanciate a runner, that will save the run statistics within the log_path file, to be parsed and processed\n",
    "# by the scoring program\n",
    "phase_runner = pypownet.runner.Runner(environment, submitted_controler, verbose=True, vverbose=False,\n",
    "                                      log_filepath=log_path)\n",
    "phase_runner.ch.setLevel(logging.ERROR)\n",
    "# Run the planned experiment of this phase with the submitted model\n",
    "score = phase_runner.loop(iterations=NUMBER_ITERATIONS)\n",
    "print(\"cumulative rewards : {}\".format(score))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile example_submission/submission.py\n",
    "import pypownet.agent\n",
    "import pypownet.environment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Submission(pypownet.agent.Agent):\n",
    "    \"\"\"\n",
    "    An example of a baseline controler that randomly switches the status of one random power line per timestep (if the\n",
    "    random line is previously online, switch it off, otherwise switch it on).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        self.verbose = True\n",
    "\n",
    "    def act(self, observation):\n",
    "        # Sanity check: an observation is a structured object defined in the environment file.\n",
    "        assert isinstance(observation, pypownet.environment.Observation)\n",
    "        action_space = self.environment.action_space\n",
    "\n",
    "        # Create template of action with no switch activated (do-nothing action)\n",
    "        action = action_space.get_do_nothing_action()\n",
    "\n",
    "        # Select lines to switch\n",
    "        if True :\n",
    "            lines_load = observation.get_lines_capacity_usage()\n",
    "            nb_lines = len(lines_load)\n",
    "            assert nb_lines == action_space.lines_status_subaction_length\n",
    "            for i in range(nb_lines):\n",
    "                lines_status = action_space.get_lines_status_switch_from_id(action,i)\n",
    "                if lines_status == 0:\n",
    "                    action_space.set_lines_status_switch_from_id(action=action,line_id=i,new_switch_value=0)\n",
    "                if lines_load[i] > 1:\n",
    "                    action_space.set_lines_status_switch_from_id(action=action,line_id=i,new_switch_value=1)\n",
    "                    action_name = 'switching status of line %d' % i\n",
    "                    if self.verbose:\n",
    "                        print('Action chosen: ', action_name, '; expected reward %.4f' % reward)\n",
    "\n",
    "\n",
    "        # Test the reward on the environment\n",
    "        reward_aslist = self.environment.simulate(action, do_sum=False)\n",
    "        reward = sum(reward_aslist)\n",
    "        if self.verbose:\n",
    "            print('reward: [', ', '.join(['%.2f' % c for c in reward_aslist]), '] =', reward)\n",
    "\n",
    "\n",
    "        return action\n",
    "\n",
    "        # No learning (i.e. self.feed_reward does pass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
