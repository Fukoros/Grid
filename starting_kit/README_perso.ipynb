{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'example_submission/'\n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "input_dir = 'public_data/'\n",
    "output_dir = 'output/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir);\n",
    "path.append(input_dir); path.append(output_dir);\n",
    "%matplotlib inline\n",
    "# Uncomment the next lines to auto-reload libraries (this causes some problem with pickles in Python 3)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chronics  configuration.yaml  reference_grid.m\r\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'public_data/hard'              # Change this to the directory where you put the input data\n",
    "!ls $data_dir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom reward signal CustomRewardSignal of file /home/nicolas/test/Grid2/starting_kit/public_data/reward_signal.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ====================================================\n",
      "                     GAME PARAMETERS\n",
      "  ====================================================\n",
      "    hard_overflow_coefficient: 1.0\n",
      "    loadflow_backend: pypower\n",
      "    loadflow_mode: AC\n",
      "    max_number_loads_game_over: 6\n",
      "    max_number_prods_game_over: 3\n",
      "    max_seconds_per_timestep: 1.0\n",
      "    n_timesteps_consecutive_soft_overflow_breaks: 10\n",
      "    n_timesteps_hard_overflow_is_broken: 10\n",
      "    n_timesteps_horizon_maintenance: 48\n",
      "    n_timesteps_soft_overflow_is_broken: 10\n",
      "  ====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypownet.environment\n",
    "import pypownet.runner\n",
    "data_dir = 'public_data'  \n",
    "environment = pypownet.environment.RunEnv(parameters_folder=os.path.abspath(data_dir),\n",
    "                                              game_level=\"hard\",\n",
    "                                              chronic_looping_mode='natural', start_id=0,\n",
    "                                              game_over_mode=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring metric: reward\n"
     ]
    }
   ],
   "source": [
    "from scoring_program import libscores\n",
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5974044799804688e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomAgent(pypownet.agent.Agent):\n",
    "    \"\"\"\n",
    "    An example of a baseline controler that randomly switches the status of one random power line per timestep (if the\n",
    "    random line is previously online, switch it off, otherwise switch it on).\n",
    "    \"\"\"\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "    \n",
    "    def act(self, observation):\n",
    "        \"\"\" Produces an action given an observation of the environment. Takes as argument an observation of the current\n",
    "        power grid, and returns the chosen action.\"\"\"\n",
    "        # Sanity check: an observation is a structured object defined in the environment file.\n",
    "        assert isinstance(observation, pypownet.environment.Observation)\n",
    "        #print(\" DO NOTHING AGENT !!! \")\n",
    "        action_space = self.environment.action_space\n",
    "\n",
    "        # Implement your policy here\n",
    "        # Example of the do-nothing policy that produces no action (i.e. an action that does nothing) each time\n",
    "        do_nothing_action = action_space.get_do_nothing_action()\n",
    "\n",
    "        # Sanity check: verify the good overall structure of the returned action; raises exceptions if not valid\n",
    "        assert action_space.verify_action_shape(do_nothing_action)\n",
    "        return do_nothing_action\n",
    "\n",
    "        # No learning (i.e. self.feed_reward does pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import time\n",
    "start = time.time()\n",
    "NUMBER_ITERATIONS = 1000\n",
    "\n",
    "submission_dir = 'example_submission'\n",
    "sys.path.append(submission_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "log_path = os.path.abspath(os.path.join(output_dir, 'runner.log'))\n",
    "\n",
    "\n",
    "open(log_path, 'w').close()\n",
    "submitted_controler = CustomAgent(environment)\n",
    "# Instanciate a runner, that will save the run statistics within the log_path file, to be parsed and processed\n",
    "# by the scoring program\n",
    "phase_runner = pypownet.runner.Runner(environment, submitted_controler, verbose=True, vverbose=False,\n",
    "                                      log_filepath=log_path)\n",
    "phase_runner.ch.setLevel(logging.ERROR)\n",
    "# Run the planned experiment of this phase with the submitted model\n",
    "score = phase_runner.loop(iterations=NUMBER_ITERATIONS)\n",
    "print(\"cumulative rewards : {}\".format(score))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <b> Save the best agent </b> it should be a class Submission and save in \"example_submission/submission.py\".  Uncomment the line <i>%%writefile example_submission/submission.py to save the agent. </i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%writefile example_submission/submission.py\n",
    "import pypownet.agent\n",
    "import pypownet.environment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Submission(pypownet.agent.Agent):\n",
    "    \"\"\"\n",
    "    An example of a baseline controler that randomly switches the status of one random power line per timestep (if the\n",
    "    random line is previously online, switch it off, otherwise switch it on).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        self.verbose = True\n",
    "\n",
    "    def act(self, observation):\n",
    "        # Sanity check: an observation is a structured object defined in the environment file.\n",
    "        assert isinstance(observation, pypownet.environment.Observation)\n",
    "        action_space = self.environment.action_space\n",
    "\n",
    "        # Create template of action with no switch activated (do-nothing action)\n",
    "        action = action_space.get_do_nothing_action()\n",
    "\n",
    "        # Select lines to switch\n",
    "        if True :\n",
    "            lines_load = observation.get_lines_capacity_usage()\n",
    "            nb_lines = len(lines_load)\n",
    "            assert nb_lines == action_space.lines_status_subaction_length\n",
    "            for i in range(nb_lines):\n",
    "                lines_status = action_space.get_lines_status_switch_from_id(action,i)\n",
    "                if lines_status == 0:\n",
    "                    action_space.set_lines_status_switch_from_id(action=action,line_id=i,new_switch_value=0)\n",
    "                if lines_load[i] > 1:\n",
    "                    action_space.set_lines_status_switch_from_id(action=action,line_id=i,new_switch_value=1)\n",
    "                    action_name = 'switching status of line %d' % i\n",
    "                    if self.verbose:\n",
    "                        print('Action chosen: ', action_name, '; expected reward %.4f' % reward)\n",
    "\n",
    "\n",
    "        # Test the reward on the environment\n",
    "        reward_aslist = self.environment.simulate(action, do_sum=False)\n",
    "        reward = sum(reward_aslist)\n",
    "        if self.verbose:\n",
    "            print('reward: [', ', '.join(['%.2f' % c for c in reward_aslist]), '] =', reward)\n",
    "\n",
    "\n",
    "        return action\n",
    "\n",
    "        # No learning (i.e. self.feed_reward does pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background:#FFFFAA\">\n",
    "<h1> Step 3: Making a submission </h1> \n",
    "\n",
    "<h2> Unit testing </h2> \n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>submission.py</code> in the <code>starting_kit/example_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. \n",
    "<br>\n",
    "Keep the sample code simple.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python $problem_dir/ingestion.py $input_dir $input_dir/res $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background:#FFFFAA\">\n",
    "Also test the scoring program:\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_output_dir = 'output'\n",
    "!python $score_dir/evaluate.py $input_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Preparing the submission </h1>\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = 'sample_code_submission_' + the_date + '.zip' \n",
    "zipdir(sample_code_submission, model_dir) \n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
